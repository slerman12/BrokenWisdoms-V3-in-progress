<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e8deed05-4b48-4844-ac9b-ffa98b680efe">
 <picture>
   <source width="82%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e8deed05-4b48-4844-ac9b-ffa98b680efe">
   <img width="82%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e8deed05-4b48-4844-ac9b-ffa98b680efe">
</picture>
</a>
</p>

# Part 8.1

- **University PhD advisor and PI**

## Dyada Sláva

My uncle ("dyada") came over, quickly. I interviewed him a bit about his physics method. A company here in America hired him, because he was the only one who knew how to do something, something specific to lens-manufacturing. He was/is an optics physicist. One part of what he did, besides dunking a lens into some liquid to create a gradient, or something like that, was, before he retired in... I think 2022... identifying a certain part of the lens or stage in the process manually.

I told him a neural network could probably do it, with enough training data. So I inquired. He didn't want to share, thought I would find it boring, but I told him "For my PhD." 

Did I intend to do it for my PhD, identity patterns for his physics (specifically, optics) work with neural networks? No. But I was curious and thought maybe I could.

So he described his method to me in detail, and left.

It was cool.

That same work week, Chenliang notifies me by Zoom that he wants me to join Niaz's lab, a Materials Science group that is trying to identify diffraction patterns using neural networks. Diffraction is a standard optics process, whereby light spreads due to obstacles or gaps in surfaces.

It was quite the synchronous timing, but at that point, I was used to synchronous timing, and just believed that the synchonicities must've had a point, especially since I had been developing my own AI/physics-hybrid concept for the last few years. So I gratefully joined Niaz's group for funding, thinking it was purposed, even though it wasn't my choice, since Chenliang made me, even while working alongside his Computer Vision lab primarily.

<!--
My uncle told me about his PhD years in Uzbekistan. His PhD took longer than usual, as he kept having to do work for others, assigned to labs and tasks, as others got PhDs and promotions through his exploited work. 
-->
One other thing my uncle told me was that he spent longer than usual on his PhD, as he kept having to do work for others, and giving others PhDs and promotions, through his exploited work.

<!--
Since being terminated, I came up with a diffraction model that is unified with Einstein in a physics theory I credit to my uncle's spirit, most likely, but it was hard work to sit and learn all the material and derive it, and in this book, I've just included some trace evidence of that knowledge — again, all my work, not my uncle's — [here](Philosophy/Velocity-Addition-Formula.md). 
-->

More work than anyone, literal torture, no thank yous. 

## Niaz Abdolrahim

<p align="center">
<a href="https://github.com/user-attachments/assets/7ab614f6-9c42-49ce-8999-d97d117b61b8">
 <picture>
   <source width="58%" media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/b33c2833-8213-4b8c-b8c3-6074f0f18489">
   <img width="58%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/user-attachments/assets/7ab614f6-9c42-49ce-8999-d97d117b61b8">
</picture>
</a>
</p>

In my fourth year, I was assigned to also work in the Mechanical Engineering group that Niaz (who was a great PI) led. Then in my 6th year, it was still while working half-part there, with Niaz, Chenliang, and team, that Chenliang (who symbolically led the deep learning side of the work, with me leading the deep learning side of the work) called me into his office in the CS building where his lab meetings, including me (both my office and attendance to those meetings, as well), were held, towards which most of my 70-hour-per-week labor was going, to inform me that he didn't think I had enough papers (this was while he knew we were in the middle of a paper-review, a paper on which I had second-author, on which Chenliang, and according to Chenliang, Niaz, had previously offered me first-author — and I rejected — twice — out of fairness to the other PhD student — for a paper that got highly positive reviews), and due to that low number of publications, he would be deserting.

The paper got accepted, after my termination notice and on the day before my last day as an employed student, in fact, synchronistically, a minute after I referenced it in the email I sent shown in the next ["Disproof"](3-Disproof.md#email-10302023) chapter.

Chenliang put me on the Mechanical Engineering lab as the source of my funding, on a project which I led, which was funded by two pretty-major grants that I helped write, which included my ideas, which somehow, by Chenliang's and very-much-not-Niaz's decision, wouldn't fund me any longer.

Niaz, not an "opposing view," and someone I really like, was my other Principal Investigator next to Chenliang. Oh but to be clear, I was still in Chenliang's lab and reporting to that lab as well every week. I was doing extreme amounts of work for both, the latter of which I haven't really started describing yet. 

For Niaz's group, I did a lot of programming, data generation and pipeline-optimizing; much of the systems; idea invention and schematic designing; grant-idea-providing-and-writing-and-diagram-designing; and all of the model building and experiment running and plotting.

In Chenliang's group, I was still trying to do my own research, which was pretty heavily bottlenecked. That's part of why I was practicing every discipline imaginable — from Wim Hof method freezing cold baths to Transcendental Meditation to yoga to strict steak/salmon-only diet to every asceticism I could not-hope for — to achieve the [full scope](https://github.com/AGI-init/UnifiedML-legacy) of what I wanted to do for [both](https://github.com/AGI-init/XRDs).

When Chenliang told me he couldn't be my advisor, I asked Niaz if she could be. She said the process of transferring to the mechanical engineering department formally wasn't that simple, that maybe she could contact the Dean, and that she sympathized sincerely. That was her phrasing, but her answer was a no. She also advised that I reach out to the CARE Network, something I at first took some mild offense to, because I messaged her on Slack about the key specifics of the medical institution hair and benzo trauma, and she clarified, no, she meant reaching out to them for a lawyer. I appreciated that. I'm grateful Chenliang forced me on that work because of Niaz. But I did a lot for them in the Mechanical Engineering department, concurrent with my studies in AI separately in his lab, and I had no choice because that project's grants, were funding me, and I helped write two of their big ones (endowing the pretty-small group with upwards of a million dollars), with their names as authors and me uncredited. I did a lot of engineering and data work for them that was independent to my research, that ordinarily would get paid a 6-figure salary for, while I have never been paid more than $15/hr in my life, and the termination left me with tons of student debt.

So you see, because my family was poor, my student debt (for the University of Rochester) was subsidized for as long as I was a student. So when I was terminated, that interest started accumulating, and I had/have to pay them/the lenders the large sum of money (in the above-the-Biden-loan-cancellation ranges, even the Pell grant one I would've gotten). So literally speaking, financially, I was "indebted for their services" for terminating me, which I had to swallow. This is the same University of Rochester I've been describing for multiple chapters now.

Makes me want to go #NotEnoughPapers, for the many thousands of dollars reverse-severance they gave me as gratitude.

However, that lab is the least of the work I did ([here](5-Early-work-in-program.md)/[here](6-Indebted.md)/[here](https://github.com/AGI-init/UnifiedML-legacy)/[here](https://github.com/AGI-init/XRDs)/[here](https://github.com/slerman12/Builder)/[here](https://github.com/AGI-init/Tributaries)/[here](https://docs.google.com/presentation/d/1ZQFeiOKSU2teVGg5EHlgREAi8pJY_Mr1CJ3H2pfFBfI/edit?usp=sharing)), at sometimes slave wage by force, with PhD requirements that were usually uniquely put on me, from the same institution that mutilated the hair and youth from my body and face, and neurochemically gassed my brain, then terminated me and scapegoated me for their 6 years of atrocities, negligences, and greed.

### Literally Did the Grants

- 1. I fully designed the main diagrams for the first grant
- 1. I came up with the main ideas for the first grant
- 1. I wrote parts of the first grant
- 2. I designed many diagrams for the second grant
- 2. I came up with at least one of the ideas for the second grant
- 2. I reviewed and wrote parts of the second grant

The first was approved as the main funding while I was working there.

If the second was approved for them, it was after I was terminated, meaning I was terminated before the second one, which I contributed to thoroughly, was approved, money that they've got over my terminated body.

As with the first, I helped propose, make my own diagrams, and write it, on faith, the final product, because they asked, while having other work I had to do, including extraneous research and engineering work for all of the advisors, PI, and faculty committee members.

### $22,588.89 Debt Paid

My loans stopped being subsidized because I was terminated, and I had to pay a sum $22,588.89, many thousands of which actually went directly to the University of Rochester and not a loan providing service, for being terminated. 

The subsidization was due to my family being poor, under 15k income poor. 

It is very unusual for the terminated employee to pay the severance pay.

I have no safety net for the most part, short of going into a job immediately after 6 years of torture, or turning to my middle class distant relatives, uncle, sister, or I suppose, a historically unprecedented number of independent medical malpractices and workers abuse injuries and the legal system. 

The legal battle against the entirety of the University of Rochester<!--, known for [retaliatory practices](),--> would be sort of horrifying and embarassing, and sort of sullying the historical physics and AI work I’ve done making me dependent on a route of partial reimbusement that isn't commensurate to the history, Biblical scientific significance, what I deserve, my ideas, my skill, my work, how much work I did, all of my 20s robbed from me, and which apparently understates the justice I'm doing to all of the people in the world, history, and possibly God (if one exists and these synchronicities are not explained by some unintelligent latent physics system) by prioritizing this route. 

Instead, I’m forced to write this book, develop my physics theory and AI without pay, and, together with my own savings, live under the support of my mom’s social security, in my childhood apartment, the same one my mom, grandparents, sister, and I <!--used to all live in-->lived in, that I had all my life since we immigrated<!--, and my own savings, still hard work, *plausibly wasted*--><!--, on good faith--><!-- even *if* I deliver, no breaks--><!--. which I thankfully scrounged up a little--><!--, while my former bosses are perhaps still being funded by--><!-- the fruit of hard work that I did for them on--><!--fruit from my good faith-->, hard work on plausibly wasted good faith. My mom is in her late 60s and I still want to have kids and for her to meet them, for her to have many years with them, more than my grandparents, who knew me through high school ([until dementia took my grandma](6.1-Medical-Malpractices.md#my-grandmas-hair-nails-and-dementia)) and college (when my grandpa [had his 4th heart failure](6.1-Medical-Malpractices.md#how-my-grandpa-died)) respectively, did with me, my other main two parents already lost. As a kid I always imagined myself getting married in my early 20s. My grandma wanted to live to my wedding. <!--Dyada Sláva is almost a couple of years into his 70s.--> <!--My other uncle yet more. --><!--My sister is 5 years older than me. My cousins are 6 and some amount years older than me. All of them have their own independent lives, husbands, families, and children.-->

The grants I helped bring in total almost a million dollars<!--, my 20s slipping every day-->. 

### Tributaries

Niaz's group also provided a GPU and I built [a general system to access it as well](https://github.com/slerman12/SweepsAndPlots), one her second-year PhD student could use, [for him, largely](https://github.com/slerman12/SweepsAndPlots/tree/main/Sweeps/XRD).

On the school's [supercomputer clusters](https://github.com/AGI-init/Tributaries/blob/main/Examples/Servers/Bluehive.py) (["Bluehive"](https://www.sas.rochester.edu/psc/assets/pdf/bluehivetutorial.pdf)) that require VPN access, [which I also automated](https://github.com/slerman12/SweepsAndPlots/blob/main/VPN.py) for us.

Building this took [time](https://github.com/slerman12/XRDs_internal/tree/master) and was emotionally supported by them.

This is no trivial thing. Bluehive is hard to use. The [library](https://github.com/AGI-init/Tributaries/tree/main) is now a general-purpose SLURM launcher.

<!--
### >$20,000 Debt

Since being terminated, I had to pay more than $20,000 of student debt, since the loans were temporarily subsidized for only as long as I was a student or PhD student. Thanks to drawing from my savings, I paid off all of it.

### Almost-Million-Dollar Grants

I came up with, proposed, taught, wrote, and made diagrams for many of the main ideas of two of their grants, totalling almost a $million brought into their institution.
-->
<!--
My advisor decided I didn’t have enough papers, just before my [next paper publication](https://docs.google.com/presentation/d/1nZFXtz2hJQlAsiLW-nuxRDPh97-UAj_g7eN326vTL8k/edit?usp=sharing) was accepted for publciation, while it was still under review with positive reviews.

For that group, [I built a whole GitHub for them, including much of the data generation and pipeline, objectively independent from anything that they could've known I was doing for my PhD, and ran all of the experiments that made it into the paper and more](https://github.com/AGI-init/XRDs/tree/main).

And helped write their almost-million-dollar grant, including coming up with, proposing, and teaching some of the main ideas, uncredited.
-->

<!--
I'm not even credited as an author on the grants, nor have been paid anything for my contribution.

That’s a lot of money I helped bring into their institution, an institution that also, independently, happens to be responsible for coerced permanent damage against me, literal torture and blatant abuse, and having paid me less than minimum wage.

Just to put this into perspective, the debt I had to pay off to them, >$20,000, is a huge-fuck-ton of money drawn from less than minimum wage savings.

During this time, I've continued my physics theory of everything, built on my philosophy work, and have been writing this book, rather than doing the world's biggest most unprecedented personal injury lawsuit in medical malpractice or worker's compensation history. 
-->

<!--
This is their million dollars. This is my $26,000. And I gave them both.
-->

### Cleaning and Generating XRD Data

I [cleaned the whole dataset generation code](https://github.com/AGI-init/XRDs/tree/main/Data), full systems top to bottom, [from its original](https://github.com/slerman12/XRDs/tree/4491888494d5dd70b908e7946769b574901346f0/Datasets/Generated).

The dataset generation is still highly inefficient. One can run it as is with python CIF.py on the Dev branch after downloading a few examples with the download() method. I have commented many suggestions for speedups but the most important one is to batch vectorize the numpy operations if possible. I highly, highly doubt this much computation is needed and I predict that some good chunk of it can be cached a priori or JITed at runtime if one is familiar with that. I've already cached the hkl matrix, removed a lot of redundant recomputations regarding the u v w augmentations by extracting it altogether, and parallelized the outer loop of the generation. It also handles automatic resuming and in the main file, downloading/souping/etc. 

Originally, the y_multi was parallelized rather than the outer loop. I kept another student's change of that but used an imap-unordered pool which is faster, BUT both of our ways might actually be slower than the original parallelizing of the y_multi. I haven't re-tested the original to compare. The speeds are not consistent with the ones two other students reported, so I suspect this is the reason. 

It would be good to measure the different computation times of each code block of process_cifs in a single pass through it. 

Note: their original dataset wasn't doing the u v w augmentations (we use multiple values for u, v, and w not just one tuple). Doing a concat of datasets would require redundantly recomputing all the non-u v w stuff as well, which includes a lot of computation. Also, in the paper, one of the uvws was randomized, and another excluded from noise augmentation. I extracted all of these to demonstrate and made it possible to move those entirely to runtime as transforms if needed.

### Programming

I did [all the programming](https://github.com/slerman12/XRDs/commits/master/).

### Experiments

I ran all the experiments.

### 2nd Publication

I’m co-author on the [paper](https://scholar.google.com/citations?view_op=view_citation&hl=en&user=3xy30K0AAAAJ&citation_for_view=3xy30K0AAAAJ:9yKSN-GCB0IC).

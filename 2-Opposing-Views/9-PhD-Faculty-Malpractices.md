
<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e8deed05-4b48-4844-ac9b-ffa98b680efe">
 <picture>
   <source width="82%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e8deed05-4b48-4844-ac9b-ffa98b680efe">
   <img width="82%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e8deed05-4b48-4844-ac9b-ffa98b680efe">
</picture>
</a>
</p>

# Part 7

- **University PhD advisors**
- **University PhD committee members**
- **University CS department Chair**

## Dyada Slava

My uncle ("dyada") came over, quickly. I interviewed him a bit about his physics method. A company here in America hired him, because he was the only one who knew how to do something, something specific to lens-manufacturing. He was/is an optics physicist. One part of what he did, besides dunking a lens into some liquid to create a gradient, or something like that, was, before he retired in... I think 2022... identifying a certain part of the lens or stage in the process manually.

I told him a neural network could probably do it, with enough training data. So I inquired. He didn't want to share, thought I would find it boring, but I told him "For my PhD." 

Did I intend to do it for my PhD, identity patterns for his physics (specifically, optics) work with neural networks? No. But I was curious and thought maybe I could.

So he described his method to me in detail, and left.

It was cool.

That same work week, Chenliang notifies me by Zoom that he wants me to join Niaz's lab, a Materials Science group that is trying to identify diffraction patterns using neural networks. Diffraction is a standard optics process, whereby light spreads due to obstacles or gaps in surfaces.

It was quite the synchronous timing, but at that point, I was used to synchronous timing, and just believed that the synchonicities must've had a point, especially since I had been developing my own AI/physics-hybrid concept for the last few years. So I gratefully joined Niaz's group for funding, thinking it was purposed, even though it wasn't my choice, since Chenliang made me, even while working alongside his Computer Vision lab primarily.

<!--
My uncle told me about his PhD years in Uzbekistan. His PhD took longer than usual, as he kept having to do work for others, assigned to labs and tasks, as others got PhDs and promotions through his exploited work. 
-->
One other thing my uncle told me was that he spent longer than usual on his PhD, as he kept having to do work for others, and giving others PhDs and promotions, through his exploited work.

<!--
Since being terminated, I came up with a diffraction model that is unified with Einstein in a physics theory I credit to my uncle's spirit, most likely, but it was hard work to sit and learn all the material and derive it, and in this book, I've just included some trace evidence of that knowledge — again, all my work, not my uncle's — [here](Philosophy/Velocity-Addition-Formula.md). 
-->

More work than anyone, literal torture, no thank yous. 

## Niaz Abdolrahim

<p align="center">
<a href="https://github.com/user-attachments/assets/7ab614f6-9c42-49ce-8999-d97d117b61b8">
 <picture>
   <source width="58%" media="(prefers-color-scheme: dark)" srcset="https://github.com/user-attachments/assets/b33c2833-8213-4b8c-b8c3-6074f0f18489">
   <img width="58%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/user-attachments/assets/7ab614f6-9c42-49ce-8999-d97d117b61b8">
</picture>
</a>
</p>

In my fourth year, I was assigned to also work in the Mechanical Engineering group that Niaz (who was a great PI) led. Then in my 6th year, it was still while working half-part there, with Niaz, Chenliang, and team, that Chenliang (who symbolically led the deep learning side of the work, with me leading the deep learning side of the work) called me into his office in the CS building where his lab meetings, including me (both my office and attendance to those meetings, as well), were held, towards which most of my 70-hour-per-week labor was going, to inform me that he didn't think I had enough papers (this was while he knew we were in the middle of a paper-review, a paper on which I had second-author, on which Chenliang, and according to Chenliang, Niaz, had previously offered me first-author — and I rejected — twice — out of fairness to the other PhD student — for a paper that got highly positive reviews), and due to that low number of publications, he would be deserting.

The paper got accepted, after my termination notice and on the day before my last day as an employed student, in fact, synchronistically, a minute after I referenced it in the email I sent shown in the next ["Disproof"](3-Disproof.md#email-10302023) chapter.

Chenliang put me on the Mechanical Engineering lab as the source of my funding, on a project which I led, which was funded by two pretty-major grants that I helped write, which included my ideas, which somehow, by Chenliang's and very-much-not-Niaz's decision, wouldn't fund me any longer.

Niaz, not an "opposing view," and someone I really like, was my other Principal Investigator next to Chenliang. Oh but to be clear, I was still in Chenliang's lab and reporting to that lab as well every week. I was doing extreme amounts of work for both, the latter of which I haven't really started describing yet. 

For Niaz's group, I did a lot of programming, data generation and pipeline-optimizing; much of the systems; idea invention and schematic designing; grant-idea-providing-and-writing-and-diagram-designing; and all of the model building and experiment running and plotting.

In Chenliang's group, I was still trying to do my own research, which was pretty heavily bottlenecked. That's part of why I was practicing every discipline imaginable — from Wim Hof method freezing cold baths to Transcendental Meditation to yoga to strict steak/salmon-only diet to every asceticism I could not-hope for — to achieve the [full scope](https://github.com/AGI-init/UnifiedML-legacy) of what I wanted to do for [both](https://github.com/AGI-init/XRDs).

When Chenliang told me he couldn't be my advisor, I asked Niaz if she could be. She said the process of transferring to the mechanical engineering department formally wasn't that simple, that maybe she could contact the Dean, and that she sympathized sincerely. That was her phrasing, but her answer was a no. She also advised that I reach out to the CARE Network, something I at first took some mild offense to, because I messaged her on Slack about the key specifics of the medical institution hair and benzo trauma, and she clarified, no, she meant reaching out to them for a lawyer. I appreciated that. I'm grateful Chenliang forced me on that work because of Niaz. But I did a lot for them in the Mechanical Engineering department, concurrent with my studies in AI separately in his lab, and I had no choice because that project's grants, were funding me, and I helped write two of their big ones (endowing the pretty-small group with upwards of a million dollars), with their names as authors and me uncredited. I did a lot of engineering and data work for them that was independent to my research, that ordinarily would get paid a 6-figure salary for, while I have never been paid more than $15/hr in my life, and the termination left me with tons of student debt.

So you see, because my family was poor, my student debt (for the University of Rochester) was subsidized for as long as I was a student. So when I was terminated, that interest started accumulating, and I had/have to pay them/the lenders the large sum of money (in the above-the-Biden-loan-cancellation ranges, even the Pell grant one I would've gotten). So literally speaking, financially, I was "indebted for their services" for terminating me, which I had to swallow. This is the same University of Rochester I've been describing for multiple chapters now.

Makes me want to go #NotEnoughPapers, for the many thousands of dollars reverse-severance they gave me as gratitude.

However, that lab is the least of the work I did ([here](5-Early-work-in-program.md)/[here](6-Indebted.md)/[here](https://github.com/AGI-init/UnifiedML-legacy)/[here](https://github.com/AGI-init/XRDs)/[here](https://github.com/slerman12/Builder)/[here](https://github.com/AGI-init/Tributaries)/[here](https://docs.google.com/presentation/d/1ZQFeiOKSU2teVGg5EHlgREAi8pJY_Mr1CJ3H2pfFBfI/edit?usp=sharing)), at sometimes slave wage by force, with PhD requirements that were usually uniquely put on me, from the same institution that mutilated the hair and youth from my body and face, and neurochemically gassed my brain, then terminated me and scapegoated me for their 6 years of atrocities, negligences, and greed.

<!--
### >$20,000 Debt

Since being terminated, I had to pay more than $20,000 of student debt, since the loans were temporarily subsidized for only as long as I was a student or PhD student. Thanks to drawing from my savings, I paid off all of it.

### Almost-Million-Dollar Grants

I came up with, proposed, taught, wrote, and made diagrams for many of the main ideas of two of their grants, totalling almost a $million brought into their institution.
-->
<!--
My advisor decided I didn’t have enough papers, just before my [next paper publication](https://docs.google.com/presentation/d/1nZFXtz2hJQlAsiLW-nuxRDPh97-UAj_g7eN326vTL8k/edit?usp=sharing) was accepted for publciation, while it was still under review with positive reviews.

For that group, [I built a whole GitHub for them, including much of the data generation and pipeline, objectively independent from anything that they could've known I was doing for my PhD, and ran all of the experiments that made it into the paper and more](https://github.com/AGI-init/XRDs/tree/main).

And helped write their almost-million-dollar grant, including coming up with, proposing, and teaching some of the main ideas, uncredited.
-->

<!--
I'm not even credited as an author on the grants, nor have been paid anything for my contribution.

That’s a lot of money I helped bring into their institution, an institution that also, independently, happens to be responsible for coerced permanent damage against me, literal torture and blatant abuse, and having paid me less than minimum wage.

Just to put this into perspective, the debt I had to pay off to them, >$20,000, is a huge-fuck-ton of money drawn from less than minimum wage savings.

During this time, I've continued my physics theory of everything, built on my philosophy work, and have been writing this book, rather than doing the world's biggest most unprecedented personal injury lawsuit in medical malpractice or worker's compensation history. 
-->

<!--
This is their million dollars. This is my $26,000. And I gave them both.
-->

### Literally Did the Grants

- I fully designed the main diagrams for the first grant
- I came up with the ideas for the first grant
- I designed many of the diagrams for the second grant
- I came up with one of the ideas for the second grant
- I wrote parts of both grants

The first was approved as the main funding while I was working there.

If the second was approved for them, it was after I was terminated, meaning I was terminated before the second one, which I contributed to, was approved, money that they got over my terminated body.

As with the first, I helped propose, make my own diagrams, and write it, on faith, the final product, because they asked, while having other work I had to do, like meeting Chris Kanan’s suggestion or the weekly meetings to Chenliang and Niaz, to whom both I had to answer to research and engineering work.

### $22,588.89 Debt Paid

My loans stopped being subsidized because I was terminated, and I had to pay $22,588.89, some of which actually went directly to the University of Rochester and not a loan providing service, for being terminated. 

The subsidization was due to my family being poor, lower-lower class poor. 

I have no safety net for the most part, short of going into a job immediately after 6 years of torture, or turning to my middle class distant relatives, uncle, sister, or I suppose, a historically unprecedented number of independent medical malpractices and workers abuse injuries and the legal system. 

But that would be sort of sullying the historical physics and AI work I’ve done making me dependent on an undignified route of partial reimbusement that doesn’t appreciate how much work I did, my ideas, and all of what was robbed from me. 

Instead, I’m writing this book and living under the support of my mom’s social security, and my own savings, still hard work, probably wasted, on good faith.<!-- which I thankfully scrounged up a little, while my bosses are being funded by the fruit of hard work that I did for them on *good faith*-->

The grants I helped bring in total almost a million dollars. 

## Chris Kanan

<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/c2d781ac-90e2-4f78-9b12-655fec5c1acb">
 <picture>
   <source width="65%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/7ebb2cf7-49af-4d6a-bc9f-03059bf6393f">
   <img width="65%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/c2d781ac-90e2-4f78-9b12-655fec5c1acb">
</picture>
</a>
</p>

They Holocausted me.

They Holocausted me. By whatever legal definition exists, they Holocausted me. Every lawyer agrees, that by whatever legal definition exists, they Holocausted me.

Now rewind in time a bit. Not to the days of the Canaanites, but to the days before Chris Kanan.

Two of my advisors and two of my committee members deserted, for funsies, e.g. sabbaticals (I barely had time for Sabbath), promotions, retirement, funding reallocation, etc., and I was left with a brand new interim committee, consisting of Chenliang Xu, who had just announced his desertion, Charles Venuto, who worked in the Med Center and had no expertise in AI, Chris Kanan, last-minute added interim committee member, and Tom Howard, last-minute added interim committee member.

I never effectively met half of my committee, we had one 20-minute Zoom call in which I presented, and then an after-room discussion.

In defense of the committee members who agreed on the decision, most of them didn't know me and hadn't met each other or me previously, and one of them, Chris Kanan, in a kind of *deus ex machina* (or so I thought, since that should have conclusively settled it), [mis-remembered](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Deus-Ex-Memory.md) the short Zoom meeting that the four of us had (I highly recommend clicking on that link), on which these decisions from their end were based, as being 1.5 hours and twice. That is quite a lapse in memory (and Chris Kanan is the youngest). The meeting was 30 minutes, and once, as the other committee members may recall and confirm. The calendar invitation that that committee member, Chris Kanan, accepted, wrote: "Friday May 5, 2023 ⋅ 1pm – 1:45pm (Eastern Time - New York)" (extra lag time added). I have on email to one committee member Tom Howard that we planned half an hour: "Would you be available any of the following dates for a half-hour remote 6-month review?" It can be confirmed that it was 30 minutes in which I had to summarize 6 years of work over Zoom: 20ish minutes spent on my presentation, then 5ish minutes for their independent-room discussion and 5 minutes for their concluding remarks. 

I should add details about the work that Chris Kanan asked me to do, or suggested rather, that I followed through on. Maybe in this [chapter](3-Disproof.md) and [this one](6-Indebted.md), but see terminator-bubble-diagram immediately above and I'll summarize below.

Long-term memory is what I was working on longest. From the Spring semester of my Freshman year, 
- when I built a long-term episodic memory reinforcement learning controller on top of image features from Felzenshwalb segmentation in Chenliang Xu's machine vision class,
- to that semester where I actually did meet Tom Howard for 5 minutes and told him about using the idea for robotics when we went to his robotics lab because he took an interest (and that short exchange is the only time I talked to him prior to this),
- to email-record (e.g. with Prof. Len Schubert),
- as well as my area exam,
- as well as my thesis proposal,
- as well as what I was doing at the Med Center that Charles Venuto has email record and maybe memory of,
- up to even this meeting with the new committee, where I showed [all of what I had done on that (lifelong, adaptive, rewritable, growing, accelerated Replay Memory for use in RL or supervised learning or generative modeling) and more](https://docs.google.com/presentation/d/1ZQFeiOKSU2teVGg5EHlgREAi8pJY_Mr1CJ3H2pfFBfI/edit?usp=sharing).

Coincidentally, they all at least had evidence that this is something I was trying to do through my full PhD, and *for some reason* — I'll let you guess why — maybe didn't get to. Everybody wanted me to pursue their different independent area research. Except Chris Kanan. Who suggested, wisely, after that 20-minute Zoom meeting, by email one month after I delivered a big new research proposal as they insanely requested, that I develop a brand new reinforcement learning systems algorithm for my giant built-from-scratch deep learning library/framework [UnifiedML](https://github.com/slerman12/Builder), and I did within two months ([here is one of the commits](https://github.com/slerman12/Builder/commit/e8b896c75bdeb388995af912a25108dfa16a92f9) when I finished implementing [it, sampling without replacement within a priority, accelerated, parallelized, hard-disk-memory-mappable Replay Memory using truly-shared RAM memory, dynamically growable and rewritable and unified with supervised and generative modeling](https://github.com/AGI-init/UnifiedML/blob/ef14f7ff14b0b494d14bc8ee4bfe8925ad2a1fb3/ML/World/Replay.py#L566-L607), innovating on the state of the art reinforcement learning algorithm/system DrQV2, which very much does not do the vast majority of those things), the day before the meeting with Chenliang, when I told him about my algorithm/system in [my UnifiedML framework](https://docs.google.com/presentation/d/1ZQFeiOKSU2teVGg5EHlgREAi8pJY_Mr1CJ3H2pfFBfI/edit?usp=sharing) — and it actually is brilliant — and he liked it dismissively, then proceeded to tell me he couldn't be my advisor because I didn't have enough papers. It was a good meeting, but he didn't know what he was doing.

### UnifiedML

It is the first rewritable DataLoader that serves as a Replay for supervised, generative, and reinforcement learning as well as the novel algorithm for sampling without replacement, something that is standardly done in the former two but had never been done for priority experience replays in the latter, especially not in combination with lifelong storage capacity via [dynamic device allocation](https://github.com/slerman12/Builder/blob/64c92d7bf5c09642e161548c36625739884b01f7/UnifiedML/src/ML/World/Memory.py#L103-L107), [hard disk memory mapping](https://github.com/slerman12/Builder/blob/64c92d7bf5c09642e161548c36625739884b01f7/UnifiedML/src/ML/World/Memory.py#L524-L543), and [truly-shared in-RAM adaptive memory](https://github.com/slerman12/Builder/blob/64c92d7bf5c09642e161548c36625739884b01f7/UnifiedML/src/ML/World/Memory.py#L59-L150), in other words though extremely reductive: an accelerated parallelized DataLoader whose contents can be changed by the agent, and which include generalized sampling methods even when the dataset size is growing such as in a priority experience replay in reinforcement learning for DataLoader, and all of this added with a truly state of the art reinforcement learning algorithm/system DrQV2 as well as others with support for continuous and discrete domains, online or offline learning, and on-policy or off-policy, all of which — yes, all of which — I generalized into a unified API and framework to fully support supervised, generative, and reinforcement learning, the most general DataLoader/Experience Replay/Memory ever built, capable also of storing and updating parameters, not just data, meaning all of this with support for deep neural Memory, not just dataset-centric. 

Nothing like it exists — I'm afraid PyTorch or somebody will try to copy it upon reading this. The value of it was so immense and this brand new interim committee — all except Chris Kanan — had not the faintest scent of that — well, that's not true, Chenliang thought I could start a business and just cared about papers, but note, I needed his GPUs to finish. By the way, pretty much fully implemented, [and elegantly so](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/World/Memory.py) (but with no GPUs to finalize the small amount of work left on the library/framework as a whole, nor funding or undestroyed-human-spirit left to write the immense amount of documentation still needed, and personally, I think this book takes priority, not to mention, I've released all the code open-source under the MIT license, so traditional funding routes aren't an option anyway, plus I have other interconnected plans for my research, if given the reigns/money-rains to make it happen). 

Since I started building it for my PhD (from about 2021, in Chenliang's lab, onwards), some similar works have come out, like [PyTorch's entire reinforcement learning library](https://github.com/pytorch/rl), but none compare (the system was being built within a [GATO](https://arxiv.org/abs/2205.06175)/[JEPA](https://arxiv.org/abs/2301.08243)-type framework before either of those were published/announced). And has an [interface that plug-and-play substitutes the normal PyTorch DataLoader](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/World/Replay.py). It's also accelerated and faster in every substantive way for supervised, too, at least than Pytorch's default DataLoader, but has all of the groundwork for the more intricate accelerators (while serving *all* the aforementioned purposes), and was the first infrastructure in Chenliang Xu's Computer Vision lab [capable of training ImageNet efficiently from scratch](https://github.com/slerman12/Builder/blob/main/tributaries-ml/src/tributaries/Examples/Sweeps/ImageNet.py), something not one other student in his Computer Vision lab — even with the most published papers — had (and probably "has" as of time of writing) ever done. To be clear, I was the first student in his PhD lab's history — officially ranked one of the [top in the world in Computer Vision](https://csrankings.org/#/fromyear/2020/toyear/2024/index?vision&us) — to use any infrastructure (his or otherwise) for training ImageNet from scratch (meaning, not via fine-tuning an ImageNet-pre-trained model, nor just using a subset of the ImageNet dataset), the gold standard of his field, all within a GATO/JEPA type generalized (and more general than either of them) framework (whose construction also preceded both of those, by the way). That being said, his students, perhaps more so than Chenliang, appreciated what I was doing, though Chenliang knew it could've been valuable, and was good enough for a PhD. Both he and Niaz said I was ready to defend. Chenliang wanted me to write my thesis before he cut his funding, yet again on an impossible deadline. But a thesis is more important than a conference paper, and I couldn't have.

### Actor Critic Creator Framework

> To do

> Much of what UnifiedML is: a GATO/JEPA type framework, implemented (unlike JEPA), started before GATO, and more general than GATO, open-sourced this whole time, and meant from the ground up for open-source and democratized understanding and use and therefore built really simply and beautifully

Describing this is hard because it was so much work that is currently unappreciated that my soul hurts even thinking

But best way would probably be bullets listing the different blocks with links to the corresponding diagrams and descriptions<!-- in the to-be-finished documentation-->

### B-, or "Sam Hasn't Been Put Through Enough Systems, the Sequel-Sequel"

I had to retake a grad-level systems class, on account of getting a tiny fraction of a point below B, and the professor, having decided my research wouldn't independently involve enough systems work, chose to not give me that tiny fraction of a point, so I ended up with a B-, the CS department PhD program requires a B or higher, and I had to take a whole semester <!--, in my 3rd year, during benzo recovery, --> of grad-level systems again, systems being my least favorite subfield of CS, and ended up mostly teaching the class anyway since it had to do with a topic that would, later, end up being taken over by AI. Chris Kanan, having suggested I implement a novel RL systems algorithm for my research, and me actually having done so in a 2 month time span, a huge, insane amount of work, disproved that earlier professor, and puts the school in debt for my retaking a grad-level systems class, and the teaching I did for it.

### Sampling Without Replacement in RL Description

> To do: Summarize this without out-of-context linguistics

In supervised learning, it's standard to sample from the dataset without replacement. This is easy to do for large datasets by parallelizing, multiple CPU workers pulling data from a fixed dataset.

> bad linguistics start here:
>
> That isn't the case for reinforcement learning, where the dataset is online, meaning it grows, it changes, data can be added, updated, or deleted. This also isn't necessarily easy to do, with parallelization, in curriculum learning. 
>
> Partitioning a changing dataset across multiple parallel devices, and keeping track of samples across all of them such that custom dataset-wide sampling algorithms, like the simple and novel sampling-without-replacement-in-RL one I made, so that they do not conflict, and keeping that efficient, using truly-shared RAM memory and memory mapping, was a big unsolved problem for me to come up with, solve, and fully program in 2 months.
>
> I built the first parallelized sampler for reinforcement learning that does sampling without replacement, which is algorithmically better in supervised learning. It supports curriculum learning, and is part of a concrescent framework supporting also generative modeling, real-time online or offline RL, and every other training paradigm. It also supports custom sampling methods, definable as if one were defining for an unparallelized framework.
>
> It's a paralellization and training system that is built to be usable and used for any, general-purpose use.
>
> In reinforcement learning, this is a big change from the baseline algorithm, DrQV2, since that algorithm requires some minimum number of workers, and doesn't generalize to no-parallelization, nor support different sampling strategies with parallelization. Mine does all of that, with no loss in performance. It's a huge amount of systems work to build a new parallelization algorithm.
>
> I more than satisfied Chris Kanan's request for a novel RL systems algorithm. The algorithm itself, "sampling without replacement," is novel for RL too and has many challenges, like the added data needing new indices across all of the devices, such that any device can sample from those new indices, pulling that data efficently without conflict.
>
> To do: write this without Michael Scott in my head causing the writing to be much stupider than me and "not explain clearly how big the contributions were, even for a long timespan." (...and explain clearly)
>
> Wernicke's and Broca's area create systems of actual opposition in a person's own linguistics. In this case, Psyche is very likely the linguistic. Or the context of GitHub. But most likely Michael.

## Tom Howard

<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/85a04ddb-b8f6-4d0c-abac-3e407d34b7a0">
 <picture>
   <source width="55%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/729c7861-768d-4562-aa28-7bc505205e13">
   <img width="55%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/85a04ddb-b8f6-4d0c-abac-3e407d34b7a0">
</picture>
</a>
</p>

The independent-room discussion reasonably marked the end of my portion of the meeting, or so I thought. However, after the independent-room discussion, we kept talking, I left, and Chenliang later told me that the committee members thought I dropped the line early. That was a misunderstanding. I really thought the meeting was over since they conveyed everything I had to do next, or at least that they were going to in that discussion. At the very, very end of the discussion, one of the committee members, Tom Howard, said, "I just want to add, I think it's important." I actually in my sleep deprivation thought he meant my work (I suspect he probably meant the chapter-list), so I did a sincere and prolonged "bless you" sign with my hands in the silence and left. I know that this is the least believable part. Chenliang knew via Slack I hadn't slept that whole night, due to insomnia and maybe-nervousness, and I mentioned that "I didn't sleep all night" during the meeting to which I think Tom Howard off-handedly, maybe-non-noticedly said "I know," before resuming his point. 

Chenliang had to take his dog to the vet, for that matter. Either his wife did or him, but the meeting had to be no more than half an hour by what he told me. How we scheduled, over Slack. 
- If I left early, it's further justified by what Chenliang wrote to me on Slack, about needing to take his dog to the vet immediately after the meeting, assumed 30 minutes, his wife possibly being able to do it, or otherwise having to reschedule the vet to later in the day, all of which probably can be verified with either his vet or his wife or just his calendar.

He (Tom Howard) concluded the meeting saying "I just want to add, I think it's important" in reference to the chapter-list, and I did a "bless you" sign with my hands, as I'd on previous occasion felt the need to do after a robotics-related pitch to Chenliang's group coincidentally, in-person in Chenliang's lab, and robotics is Tom Howard's field. That was a coincidence though. It was just a vivid moment in Chenliang's lab, with all of his students there as witnesses, when he agreed to buy me one of the $300 Bittle robots that I could use with the robotics software that I [built](https://github.com/AGI-init/tributaries/blob/main/Examples/Sweeps/Bittle.py), that I did a "bless you" sign for in gratitude. I meant it in a similar way to Tom Howard, but I interpreted "I just want to add, I think it's important" as being in reference to my research, not the chapter-list.

The chapter-list was the only requirement they wanted to make in that meeting. We had the entire after-independent-room discussion and they didn't specify anything other than the chapter-list. I'm sure they weren't going to. Perhaps one of them can even confirm that nothing more than the chapter-list was discussed as extra requirement in their independent-room meeting. That was clear from context.

But afterwards, I got an email — I think from Chenliang and perhaps from the graduate coordinator — specifying two altogether different requirements, with only an auxiliary mention of the chapter-list. Here they were, as apparently decided by the committee (post-hoc) after their chapter-list decision in the actual six-month review:

> ### $\Huge &#8220;$
> As remediation, the committee asks the student to
>
> 1.   before June 5, 2023, provide a 1-page write up that addresses the problem statement, hypothesis, and approaches of the thesis and give an outline of thesis chapters,
> 2.    before August 30, 2023, re-do and pass a six-month review.
> ### $\Huge &#8221;$

It's ironic that I'm being asked for remediation.

I don't know who decided these extra requirements, if it was the CS chair Michael Scott, or Tom Howard, or Chris Kanan, or even Chenliang.

I delivered a 6-page write up, as well as a chapter-list, as well as a 1-page write up summary in the 6-page write up, meeting all of the requirements of (1) for this brand new interim committee that effectively never met me. 

Subsequently, Chris Kanan suggested that I innovate a new reinforcement learning systems-based algorithm (also suggesting it post-hoc), which I did, as I described [above](#chris-kanan).

These are enormous requirements that I met on their behalf.

Tom Howard didn't make any tangible, explicit, or otherwise suggestions, nor did my advisor or Charles. (The committee consisted of 4 people, my advisor Chenliang, Chris Kanan, Tom Howard, and Charles).

The actual six-month review was **May 5th, 2023**. Then Chenliang notified me of his desertion on **July 24th, 2023**, a day after I finished implementing the [novel reinforcement learning systems-based algorithm](https://github.com/AGI-init/UnifiedML/blob/ef14f7ff14b0b494d14bc8ee4bfe8925ad2a1fb3/ML/World/Replay.py#L566-L607) (and [here](https://github.com/slerman12/Builder/commit/e8b896c75bdeb388995af912a25108dfa16a92f9) is the specific commit), and Chenliang confirmed by email the desertion for the rest of the committee and Michael Scott on **August 10th, 2024**, the same day as my [early in-advance-of notice](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Not-Enough-Carbs.md) to the committee and Michael Scott that, on account of that, I wouldn't attend the requirement (2), notified to them without their "no" prior to the **August 30, 2023** date, with Chenliang even specifying that I was ready to defend a thesis within the next few months.

### Employer "Affirmative Consent" isn't a Thing

What do I mean by 'without their "no"'? I mean, I told them I wasn't going to make the make-up meeting, and gave them the reason why. They didn't reply affirmatively or negatively. As my employers, given one-month's advance notice, it is their responsibility to reply "no," or otherwise, no news is presumed good news, and missing that meeting, as I'd warned advance of and had a more than good excuse, cannot be used as the sole termination reason. However, even if it is, that will later be addressed too, in accord with their own policy.

Also, the meeting itself was based on their false premise.

For the most part, they ignored all of my emails where I explained everything to them, and want me to what—sit by their bedside and read everything word by word to them? More than 3 major emails (the advance notice one that I was going to miss the meeting, as well two other pretty long, exhaustively descriptive ones), that all of them, or at least Michael and Chenliang, got. Others about my research specifically that my committee got. And, besides the occasional reply, e.g., Chris Kanan suggesting I implement an entire new RL systems algorithm before the next make-up (which I did), ignored, as if their employer relationship excuses them from having to acknowledge information that changes the context of what can reasonably be used as a termination reason.

The truth is, these academics want to be seduced (e.g., "flying colors") or given courtesies (even when it's at the huge sacrifice cost of the employee). They don't care about research quality, and, as will be shown later, their own policy, by which they justify their employee mishandling.

...especially on an inaction, employer "affirmative consent," given advance notice, isn't a thing.

1. 3 week's advance notice from employee. <!--(after advisor deserts)-->
2. With a *really* good provided excuse<!--, due to one of the employers in the first place-->. <!--(second advisor deserted)-->
3. And as will be shown later, the employer violated the policy handbook that requires the action.
4. And the action itself, in the employee's case, wasn't justified. <!--(advisor writes in reply that student is ready to defend)-->

### Real-Time RL Robotics

In case the detail was missed, since Tom Howard's field is robotics, UnifiedML supports [real-time RL robotics](https://github.com/AGI-init/tributaries/blob/main/Examples/Sweeps/Bittle.py). It was one of the [first works to do so, before the idea gained popularity](https://github.com/PetoiCamp/OpenCat/issues/30). It was one of many [contributions](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/World/Environments/Bittle.py) and innovations I had to quickly go through in our one and only meeting with this interim group.

### Bittle Fast Description

First I wasn’t able to do the robot tracking with [YOLO V7](https://arxiv.org/abs/2207.02696) and then [YOLO V8](https://arxiv.org/abs/2305.09972), because those cannot recognize the Bittle robot, and had to do the Bittle robot object detection [by sticking in a fork](https://github.com/user-attachments/assets/e178954e-64ad-4606-a36d-61adb8cff803).

Then I [got it to work](https://github.com/user-attachments/assets/8ffed7ff-f682-4717-94a7-a3283b3ffa8b) with [GroundingDINO](https://arxiv.org/abs/2303.05499), a foundation model that UnifiedML [supports the quick use of](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/Agents/Blocks/Architectures/Vision/FoundationModels/GroundingDINO.py), and [which wasn’t entirely easy to integrate](https://github.com/continue-revolution/sd-webui-segment-anything/issues/162).

In both vision model cases, it was a full <!--end-to-end--> framework for livestreaming data in real-time [from Youtube](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/World/Datasets/YouTube.py) ([implemented with VidGear](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/World/Datasets/YouTube.py) for supervised/demo-learning [and CamGear](https://github.com/slerman12/Builder/blob/main/UnifiedML/src/ML/World/Environments/YouTube.py) for real-time RL), filmed live from a smartphone, in a democratized setup that anyone can use, the first robotics infrastructure that one can pick up quickly and watch the robot learn in real-time, indoors or outdoors, ideally such that even a child could [afford](https://www.petoi.com/products/petoi-robot-dog-bittle-x-voice-controlled?utm_source=googleads&utm_medium=cpc&utm_campaign=Robotics-BittleX-PMax&utm_term=&utm_content=&gad_source=1&gbraid=0AAAAACJ6OErS_eDYe8R878GQC6Qvnhaii&gclid=CjwKCAiAmfq6BhAsEiwAX1jsZ4eTl3TUdSoS-Ghns6vNBs6NAkDpzdVQYQT0ZJjSew1A7oresxdL5BoCqkoQAvD_BwE) and train, where ordinarily robot quadrupeds in robotics setups [in the literature](https://www.science.org/doi/10.1126/scirobotics.abk2822) had cost $20,000 or more, and a serious one that affords real-time RL from YouTube for adaptive robotics setups, from [Bittle](https://github.com/PetoiCamp/OpenCat/issues/30) robots to any other, like the [$74,500 Spot robot](https://robotsguide.com/robots/spot#). Sans YouTube livestreaming (e.g., from a smartphone), the simplicity, and a general-purpose open-source framework, this strategy has become [more popular](https://youtu.be/Kf9WDqYKYQQ?si=QxJ2SkD1gvP2JzFh) since my termination.

By using Bittle, at least at the time the first to do so for real-time real-world RL, I made the first truly democratizable, affordable, and accessible <!--end-to-end-->robotics trainer.

Much of this work was done after the six-month review and before what would’ve been the next six-month review. The formal termination date was 5 months after the six-month review, 3 months after Chenliang's desertion, 2 months after the would-be make-up review. In that time, I updated the committee as much and about everything that I could’ve, given the materials and work they requested. I reported to Chenliang literally-almost everything, though six-months is how long PhD students usually get to report back to a committee, and usually with security under the grad school providing wage and advisor. 

### Art of Science Competition

I even submitted the Bittle work<!--I submitted a Bittle related artwork--> to the [University of Rochester Art of Science Competition](https://docs.google.com/presentation/d/13tAT_JixcAt1-ym_0Gcw4yZ93siCoKRCwuTxYoEFWUA/edit?usp=sharing) (as a still image), asking for Michael's advice on **03/13/23** by email, 2 months before the six-month review with the brand new committee, since he headed the CS department and no student in the University of Rochester CS department had ever had a submission win the Art of Science Competition. I showed Michael 4 different artworks. Michael advised against all of them as such:

> ### $\Huge &#8220;$
> I’m pretty sure you can find winners of past competitions online. They are mostly NOT technical diagrams but rather images that look like “real” art but come from scientific pursuits.
> ### $\Huge &#8221;$
> &ensp;&ensp;- **03/13/2023**

My original planned submission candidates were more technical, but beautiful diagrams, having to do with the intricates of the UnifiedML framework, that I'm more proud of than the new "Bittle Bots" submission artwork I made instead, after their feedback.

Chenliang proposed the submission I went with, and I made it quickly afterwards:

> ### $\Huge &#8220;$
> I agree with Michael. 
>
> Sam: one idea is to tell a story (in a picture) of the Bittle Bots trained by your UnifiedML.
> ### $\Huge &#8221;$
> &ensp;&ensp;- **03/13/2023**

So I did, submitting the [linked above](https://docs.google.com/presentation/d/13tAT_JixcAt1-ym_0Gcw4yZ93siCoKRCwuTxYoEFWUA/edit?usp=sharing) picture story (as a still image), having made it in a short amount of time.

This is meant to show that Chenliang was very supportive about my "Bittle Bots" work, even just a couple months before the six-month review, though perhaps I disagree with their unappreciation with technical diagrams, considering them to be less "'real' art." The 4 I showed were these, as follows, my favorites being "Jungly" and "Framework," and the 4th one (that I called "Public Library") was actually also proposed by Chenliang, but earlier independent the Art of Science Competition, in December, 2022, less than 6 months before the 6 month review. 

- ["Jungly"](https://github.com/user-attachments/assets/65bb23d9-0050-4c53-b873-c70f6f860c07)
- ["Squigglies"](https://github.com/user-attachments/assets/e9108af1-0d3a-4dc1-b8e6-7ae149d6f135)
- ["Framework"](https://github.com/user-attachments/assets/c865d729-e51d-4b3a-8642-aab54ff9bd60)
- ["Public Library"](https://github.com/user-attachments/assets/23c86b94-0ef7-4f72-a3da-a74a0b571ac9)

I also included this caption:

> ### $\Huge &#8220;$
> "UnifiedML is a Machine Learning bow and arrow that bullseyes-and-destroys nukes, armored tanks, and flying saucers while perched reverently in muddy camouflage on Earth’s green trees.”
>
> More philosophically, UnifiedML can be defined as an expanding ontology for the process of epistemology, however the expanding is in some way epistemelogical.
> ### $\Huge &#8221;$
> &ensp;&ensp;- **03/13/2023**

I presented these [other diagrams](https://docs.google.com/presentation/d/1ZQFeiOKSU2teVGg5EHlgREAi8pJY_Mr1CJ3H2pfFBfI/edit?usp=sharing), also elaborate technical diagrams, to try to summarize my work during my six-month review.

Well prior to that, another student set up [these training environments in Chenliang's lab]() [To do: add photos to main Github repo], hoping to work on the idea as well after I proposed it (after I had Chenliang order the bots and after I had described the methodology)—and Chenliang had wanted to apply it to a fire-fighting proof-of-concept (like a fire-fighter dog, but now in retrospect, that's a good pun for after my being fired).

Chenliang, having recognized UnifiedML as being impressive by itself for a PhD student's thesis, not to mention the XRD project which was funding me, and everything else—a GATO/JEPA type framework—believed I was ready to defend and had seen that my progress on real-time real-world RL robotics was already on top of an insightful and useful framework, and before any of the ideas had gained popularity. The new committee had not had the chance to engage as much with what I was doing, and most of them had abandoned ship as soon as the ambitiousness was even begun to be unpacked, and were already on lifeboats far away by the time the context of the information was delivered to their email inboxes after the six-month review, and still prior to the newly added make-up review deadline.

Regarding these 4 artworks, Michael did respond with a "negative non-consent," and I adhered to his and Chenliang's recommendation, submitting the "Bittle Bots" picture story. It lost. It got rejected. I was there at the Art of Science Competition and there were many better submissions that deserved the democratic vote over mine. I walked out upset, but don't disagree.

## Charles Venuto

<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/88057836-9605-4d4a-86b1-00e8bcc86148">
 <picture>
   <source width="58%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/4496d2b4-98ee-43e8-9324-64e680bd9d35">
   <img width="58%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/88057836-9605-4d4a-86b1-00e8bcc86148">
</picture>
</a>
</p>

I have to elaborate more on Charles since he was on my six-month review committee.

Charles was still on my committee from the Med Center years, but was about to be replaced after this latest six-month review by my PI of the last several years [Niaz](#niaz-abdolrahim) (the work for whom was funding me), as she'd agreed and Chenliang advised.

Charles was my Med Center advisor. Charles and Henry both oversaw me in those first 3 years, before Henry's promotion meant I had to switch into Chenliang's lab and start an altogether new Computer Vision-branch focus of research, with an ultimatum to submit a top-venue paper that summer *in* Computer Vision, literally a brand new field to me. And I did. Amazingly. Though that seems to be unappreciated (the benchmarks and conventions for actual acceptance, though not necessarily principle of concept, are more elaborate than just plopping MHDPA on top of a CNN, had I done that). However, the [explainability-centric paper that I came up with, derived, wrote, and programmed](https://arxiv.org/abs/2006.08601) would not have been my preferred research area, since I was working on MHDPA and long-term episodic memory methods for Charles in the Med Center (and Henry) prior to that, and wrote [my novel MHDPA method paper](https://www.overleaf.com/read/qgmmzgsrctmg#6cd1b9) before MHDPA had any popularity or renown outside of small groups at DeepMind. MHDPA, for the uninitiated, became the backbone, 4 years later, of foundation models like ChatGPT. Henry doubted my obsession with the method back in 2018. No one at the university heard of it. And when switching to Chenliang's lab, he wasn't too thrilled with the idea of applying it to Semantic Image Segmentation, in what would've been perhaps (with some rarely-credited DeepMind experiments at the time having already done it on CNNs as the exception) the first Vision Transformer (since it would've had to convincingly beat baseline scores on Computer Vision benchmarks, which those DeepMind experiments hadn't applied the method on, and rarely are given the credit, despite unified principle of concept). So instead, under an employment-contingent ultimatum, I co-wrote my ICCV [Taylor-CAM](https://arxiv.org/abs/2006.08601) paper under Chenliang with Henry and Charles. Charles and I managed to sneak biomedical modeling into the appendix (see Appendix J, rather invisible).

I credited Charles as co-author on that paper, however they at the Med Center did not credit me for the prototype of the disease prognostication [model]((https://github.com/slerman12/DiseaseModeling)) (since developed since that original version that won in the PPMI contest, mentioned early [above](#charles-venuto)) and [website]((https://github.com/slerman12/DiseaseModelingWebApp)) I came up with, had to argue for, built, and presented in DC in front of renowned Parkinson's disease researchers, a poster and live demo presentation that also wasn't credited (and not to mention was still amid the very peak of my benzo withdrawal, that I had to take a benzo for to present).

I haven't spoken to Charles individually since we added that biomedical component to my [Taylor-CAM](https://arxiv.org/abs/2006.08601) paper and, 3 years later (and no hostility between us), he didn't say a word during the six-month review. I mean not a word, except — maybe — hi, and his video was off. That's 1/4 of the deciding committee, whose decision hinged on that meeting (on whose decision around that meeting determined my termination), who didn't have his video on or say a word during the deciding meeting. The other two were brand new interim replacements for other committee members who were absent. So that just leaves my advisor Chenliang, who didn't want to terminate me, who just wanted to reallocate my funding from the Mechanical Engineering group due to not enough papers in his Computer Vision group, and who believed my research was satisfactory enough to defend that month (of my termination), if I just "followed [his] formatting instructions" for the thesis that I hadn't started writing, that he thought I could write quickly.

So in other words: Chris Kanan (who [didn't remember the meeting](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Deus-Ex-Memory.md)) and Tom Howard fully determined my termination, besides Michael L. Scott. 

## Recap

<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/5290be0b-5b0b-4d26-a0ed-bc6d1f7e1abd">
 <picture>
   <source width="75%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/5290be0b-5b0b-4d26-a0ed-bc6d1f7e1abd">
   <img width="75%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/5290be0b-5b0b-4d26-a0ed-bc6d1f7e1abd">
</picture>
</a>
</p>

<!--There’s an old Russian saying, "Never show a fool a job half done." I'd never think it should be, "Never show 4 fools a job 95% done."-->

## Michael L. Scott

<p align="center">
<a href="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e4938352-3a54-450f-9fc7-0a58c3530b34">
 <picture>
   <source width="55%" media="(prefers-color-scheme: dark)" srcset="https://github.com/slerman12/BrokenWisdoms/assets/9126603/a3d6987c-3e7a-4923-b311-cd0e323fe911">
   <img width="55%" alt="Text changing depending on mode. Light: 'Light' Dark: 'Dark'" src="https://github.com/slerman12/BrokenWisdoms/assets/9126603/e4938352-3a54-450f-9fc7-0a58c3530b34">
</picture>
</a>
</p>

> The [eczema this is presently giving me](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Eczema.md) as I type is severe. My arms are scathing red. I'm itchy and can't sleep, rolling around under my blankets in a burning panic, nails grinding to skin on arms, trying to shed the stress from this inflicted evil of judgment. The reader's possible mixed perceptions in my head, all the ways this could be re-done to be made more convincing and believed haunting the scorching thought rivers. Like ants on my arms literally, burning rivers as blood, my arteries need to be dug of their hidden psychological poison, my brain says; my brain pierces and threatens as it sends those coursing swarms stingingly down the lengths of my typing limbs, even now, as I try to put that burning disturbing pleasure and agony into words, if not the claws of my nails where skin residue bulks and swells. Please reader in the hidden ether, stop doing this to me. Send love, not this terror of threat and divided consciousness that broils as war between my body and the depths of my mind and senses.
>
> The torment doesn't stop until I finish this. I'm slave driven by my skin, as I was by my advisors, committees, and professors. I fear that you are all so stupid, that none of you will see the truth of this, that you will act as allies to the contagion that plagues my stress rather than as people who know the heart no matter the veil or law of land or powers that be.

Maybe one of the strongest Opposing Views, which the remainder of this book will be devoted to obliterating is the CS department Chair who comes in at this point for the first time in my PhD, Michael L. Scott (The Messenger as he'd might've called himself), or: The Judge.

His Opposing View is only strong because of its window of context. Unlike Chenliang and Charles, he didn't know me. Unlike Chris Kanan, he wasn't in my field. And unlike Tom Howard, he didn't and couldn't have even been relevant to a six-month review, since he had no background or expertise whatsoever in anything relevant to the future of his field (to be fair) or mine. The future of his field is my field, for that matter.

That makes him an extremely strong Opposing View.

Michael made a lot of false allegations prior to and after terminating me, in fact almost entirely false allegations, entirely false or hypocritical allegations. For most of the time, his belief was that he was terminating me for more serious reasons than the six-month review make-up. He believed my research was inadequate, "unviable," and that I had to propose a new research "plan." "Plan" — in one's 6th year when advisor and PI already believed I could defend on the work that I had that month.

My advisor and PI weren't right, because I needed peace to write my thesis. That's where Michael's exercise in unearned ruling authority (over me anyway) was the most extreme.

And suspicious.

I call this the Termination Slam.

His previous email read:

> ### $\Huge &#8220;$
> If I do not hear from you by 6 Oct., with a plan for successful completion, the department will terminate your stipend and discontinue your enrollment as of 31 Oct. 2023.
> ### $\Huge &#8221;$
> &ensp;&ensp;- **09/25/2023**

In other words, 'Send the department my "new research plan" (despite the advisor and PI believing I was ready to defend) by **10/06/2023**, now an added independent requirement to the previously delivered materials to the independent six-month review committee.'

Then I delivered another research plan, with precision and accuracy, by the specified date **10/06/2023**. 

This was the only reply I got, of **10/12/2023**:

> ### $\Huge &#8220;$
> Dear Sam:
>
> Thank you for your note of 6 Oct.  I have conferred with members of your committee.  They confirm that the plan you outline is neither consistent with what you originally proposed for the PhD nor a viable path to completion of the degree.  With regret, we will be terminating your student status and stipend as of the end of October.
>
> Yours,
> 
> Michael L. Scott (he/him) </br>
> Arthur Gould Yates Professor and Chair</br>
> Computer Science Department, University of Rochester</br>
> \<provided contact info redacted\>
> ### $\Huge &#8221;$
> &ensp;&ensp;- **10/12/2023**

I delivered what was requested and he put his boot down on my sincerity and effort. That boot despite what was threatened and said is why it was a Termination Slam, not just a termination. On personal and highly elaborate work that was sent to him (and CC'd Chenliang) about all of my research, and the plan to defend after I write my thesis.

Later, he specified the detail he didn't like. No no, it wasn't the research-related material, as he later self-contradicted, it was my request for "peace" towards the end.

However, this alone does not damn Michael. He was CC'd on or I sent him, *all* of the context. At first, he got the [medical context](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Not-Enough-Carbs.md) and only the research "context" from the brand new interim committee, later the research context, and gradually he realized that his only justification for the termination — despite what he previously specified — was a measly six-month review make-up, the one that was post-hoc both with respect to advisor desertion and requirement (which I warned [on **08/10/2023**](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Not-Enough-Carbs.md) I wasn't going to attend, that Michael was CC'd for), and which is a formalism that isn't under any ordinary PhD circumstance considered that important.

But at that point he stayed doubled down.

The boss battle was over, and I lost.

#

$\color{green}\text{At}$ $\color{green}\text{this}$ $\color{green}\text{time,}$ $\color{green}\text{things}$ $\color{green}\text{are}$ $\color{green}\text{dire,}$ $\color{green}\text{but}$ $\color{green}\text{in}$ $\color{green}\text{this}$ $\color{green}\text{book,}$ $\color{green}\text{I}$ $\color{green}\text{actually}$ [disproved all of Michael L. Scott's and the committee's alleged reasons](3-Disproof.md)$\color{green}\text{,}$ [twice](7-Ongoing.md)$\color{green}\text{,}$ $\color{green}\text{including}$ $\color{green}\text{mathematically}$ $\color{green}\text{(conclusively)}$ $\color{green}\text{disproving}$ $\color{green}\text{the}$ $\color{green}\text{make-up}$ $\color{green}\text{review}$ $\color{green}\text{one,}$ [believe it or not](7-Ongoing.md) $\color{green}\text{(see}$ $\color{green}\text{the}$ $\color{green}\text{Epilogue).}$ <sub>Might remove this disclaimer later, but for now, my life cannot depend on a readership's attention span any more than it already has. To be clear, what I mean is I disproved the whole constitution that they drew the make-up review requirement from, in math, and showed that they were violating their policy. That they are violating their policy. And that mathematically derived disproof [will appear in the last disproof of the file titled "7-Disproof.md,"](7-Disproof.md#disproof-7) not in the file titled "6-Opposing-Views.md."</sub>

#

Michael doesn't know this, but in the systems class I took with him in undergrad, he gave me the lowest grade I've ever gotten in any class, ever, kindergarten through PhD, in a systems class, and I do not like systems (not the coercive kind anyway). He even bumped it up a very-very little. Now Michael ultimately relayed the ruling to terminate, on the "basis" of the committee, and not one, but, as he claimed, [two](7-Ongoing.md) six-month reviews ([and this make-up!](7-Ongoing.md)). Michael mentioned the possibility of applying for reinstatement, though what that means is unclear, especially as: Did he mean I needed to find yet another advisor, new source of funding, re-take a six-month review, do my thesis, and do all of this still recovering from traumas in my 6th year, for less than New York State's legal living wage, or no pay, within the next one to few months? 

See "Slavery or impossible" [here](3-Disproof.md) (in the next chapters) for elaboration on what was demanded on me *together with* the six-month review make-up.

For all of the aforementioned reasons, and final, I was terminated without degree. 6 years of the hardest work the university has ever seen thrown away and spit on, with no accountability, from the same single monopoly and institution that induced multiple medical malpractices on me, mutilated me into looking like Gollum literally, and put me through a literal physiological coerced burning hellfire for more than a year that can't be described. Meanwhile, those years in the program involved two advisors leaving due to no fault of my own, having to work in the Medical Center and Mechanical Engineering department for funding, and a quarter to a half a year as I worked for Chenliang for free.

> ### $\Huge &#8220;$
> Hi Sam -
>
> I've received multiple emails from you over the past few days, which I wanted to acknowledge. I will not try to address each claim separately, but I disagree with many things you have said about the process of dismissing you from your academic program, including your characterization of your academic progress and of communications with you on that topic. 
>
> Yours,
>
> Michael
> ### $\Huge &#8221;$
> &ensp;&ensp;- **10/18/2023**

These are just words. He didn't acknowledge anything I said, separately or together. He occasionally wrote that he disagreed with the characterization, and made no argument as to why.

### Summary of why interim

The committee that terminated me was a brand new *interim* committee, for just one meeting, for which they post-hoc wanted a make-up before the next one that they wouldn't even attend. 

Since I had to switch advisors, and my PI Niaz agreed to be on my defense committee instead of Charles (by my advisor's suggestion just prior to the six-month review), and another committee member was returning, and assuming my old advisor would still remain on the committee, that means the entire brand new committee (3/4 members) — including all of the ones who made the termination decision and ruled that I needed a new research "plan" in my 6th year — were leaving. After that one 30-minute video call, they assumed all governing power over my studies, labor, and employment, simply because other faculty members left without warning (abandoned/deserted their "posts") last-minute. More egregiously, in case that doesn't stress it, 2/4 of them (3/5 if you count Michael) aren't in my field and have no background or expertise in my field. The only 1/4 who did, next to my advisor, was Chris Kanan, the one who provided the [Deus Ex Memory](https://github.com/slerman12/BrokenWisdoms/blob/Ancillary/Deus-Ex-Memory.md) in which he forgot the meeting, and on whose behalf I invented a new RL systems algorithm in less than 2 months during this 3 month period. 

That's the whole story, and where in there is even the slightest administrative sense or rational mandate to make life-altering decisions?

#

<!--After 6 years at the University, 10 if undergrad is counted:-->

> ### $\Huge &#8220;$
> [...] I have conferred with members of your committee. They confirm that the plan you outline is neither consistent with what you originally proposed for the PhD nor a viable path to completion of the degree. With regret, we will be terminating [...]
> ### $\Huge &#8221;$
> &ensp;&ensp;- Michael L. Scott
